{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, vgg16, inception_v3, densenet161\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Загрузка и анализ датасета EMNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Загрузка EMNIST (используем split 'balanced' для сбалансированных классов)\n",
    "train_dataset = torchvision.datasets.EMNIST(\n",
    "    root='./data', \n",
    "    split='balanced',\n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.EMNIST(\n",
    "    root='./data', \n",
    "    split='balanced',\n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Посмотрим на информацию о датасете\n",
    "print(f\"Количество классов: {len(train_dataset.classes)}\")\n",
    "print(f\"Размер тренировочного набора: {len(train_dataset)}\")\n",
    "print(f\"Размер тестового набора: {len(test_dataset)}\")\n",
    "print(f\"Классы: {train_dataset.classes}\")\n",
    "\n",
    "# Проверим дисбаланс классов\n",
    "class_counts = {}\n",
    "for _, label in train_dataset:\n",
    "    class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "print(\"\\nРаспределение классов в тренировочном наборе:\")\n",
    "for i, count in enumerate(class_counts.values()):\n",
    "    print(f\"Класс {i} ({train_dataset.classes[i]}): {count} примеров\")\n",
    "\n",
    "# Визуализация примеров изображений\n",
    "def show_examples(dataset, num_examples=10):\n",
    "    fig, axes = plt.subplots(1, num_examples, figsize=(15, 3))\n",
    "    for i in range(num_examples):\n",
    "        img, label = dataset[i]\n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Class: {label}\\n({train_dataset.classes[label]})')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_examples(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Создаем DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Функции для обучения и оценки\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Для Inception v3 нужны особые входные данные\n",
    "        if isinstance(model, torchvision.models.Inception3):\n",
    "            # Inception ожидает 3 канала и размер 299x299\n",
    "            images = images.repeat(1, 3, 1, 1)  # 1 канал -> 3 канала\n",
    "            images = torch.nn.functional.interpolate(images, size=(299, 299))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, aux_outputs = model(images)\n",
    "            loss1 = criterion(outputs, labels)\n",
    "            loss2 = criterion(aux_outputs, labels)\n",
    "            loss = loss1 + 0.4 * loss2\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            if isinstance(model, torchvision.models.Inception3):\n",
    "                images = images.repeat(1, 3, 1, 1)\n",
    "                images = torch.nn.functional.interpolate(images, size=(299, 299))\n",
    "                outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Функция для создания и модификации моделей\n",
    "def create_model(model_name, num_classes):\n",
    "    if model_name == 'resnet18':\n",
    "        model = resnet18(weights=None)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'vgg16':\n",
    "        model = vgg16(weights=None)\n",
    "        model.features[0] = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    elif model_name == 'inception_v3':\n",
    "        model = inception_v3(weights=None, aux_logits=True)\n",
    "        model.Conv2d_1a_3x3.conv = nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
    "    elif model_name == 'densenet161':\n",
    "        model = densenet161(weights=None)\n",
    "        model.features.conv0 = nn.Conv2d(1, 96, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Эксперименты с разными архитектурами\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_epochs = 3\n",
    "\n",
    "models_to_train = ['resnet18', 'vgg16', 'inception_v3', 'densenet161']\n",
    "results = {}\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = create_model(model_name, num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Критерий и оптимизатор\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    \n",
    "    # Списки для сохранения результатов\n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [], []\n",
    "    training_times = []\n",
    "    \n",
    "    # Обучение\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        training_times.append(epoch_time)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] - Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "        print('-' * 40)\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    results[model_name] = {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accs': test_accs,\n",
    "        'training_times': training_times,\n",
    "        'final_test_acc': test_accs[-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy for {model_name}: {test_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Визуализация результатов\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Графики потерь\n",
    "plt.subplot(2, 2, 1)\n",
    "for model_name, result in results.items():\n",
    "    plt.plot(result['train_losses'], label=f'{model_name} Train', linestyle='-')\n",
    "    plt.plot(result['test_losses'], label=f'{model_name} Test', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Графики точности\n",
    "plt.subplot(2, 2, 2)\n",
    "for model_name, result in results.items():\n",
    "    plt.plot(result['train_accs'], label=f'{model_name} Train', linestyle='-')\n",
    "    plt.plot(result['test_accs'], label=f'{model_name} Test', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Время обучения\n",
    "plt.subplot(2, 2, 3)\n",
    "avg_times = [np.mean(result['training_times']) for result in results.values()]\n",
    "plt.bar(results.keys(), avg_times)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Time per Epoch (s)')\n",
    "plt.title('Training Time per Epoch')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Финальная точность\n",
    "plt.subplot(2, 2, 4)\n",
    "final_accs = [result['final_test_acc'] for result in results.values()]\n",
    "plt.bar(results.keys(), final_accs)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Final Test Accuracy (%)')\n",
    "plt.title('Final Test Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.axhline(y=max(final_accs), color='r', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('emnist_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Сводная таблица результатов\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"{'Model':<15} {'Final Train Acc':<15} {'Final Test Acc':<15} {'Avg Time/Epoch':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name:<15} {result['train_accs'][-1]:<15.2f} {result['test_accs'][-1]:<15.2f} {np.mean(result['training_times']):<15.2f}\")\n",
    "\n",
    "# Находим лучшую модель\n",
    "best_model = max(results.items(), key=lambda x: x[1]['final_test_acc'])\n",
    "print(f\"\\nЛучшая модель: {best_model[0]} с точностью {best_model[1]['final_test_acc']:.2f}%\")\n",
    "\n",
    "# 8. Детальный анализ лучшей модели\n",
    "print(f\"\\nДетальный анализ лучшей модели ({best_model[0]}):\")\n",
    "print(f\"Количество параметров: {sum(p.numel() for p in best_model[0].parameters() if p.requires_grad):,}\")\n",
    "print(f\"Общее время обучения: {sum(best_model[1]['training_times']):.2f} секунд\")\n",
    "print(f\"Среднее время на эпоху: {np.mean(best_model[1]['training_times']):.2f} секунд\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
